{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('finance-model-info.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>LINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Current Asset Value Calculator</td>\n",
       "      <td>Current Asset Value Calculator aims to develop...</td>\n",
       "      <td>Link-to-model1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Potential Asset Value Calculator</td>\n",
       "      <td>Potential Asset Value Calculator is designed t...</td>\n",
       "      <td>Link-to-model2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fair Credit Calculator</td>\n",
       "      <td>Fair Credit Calculator is one initiative among...</td>\n",
       "      <td>Link-to-model3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treatment Recommendation System</td>\n",
       "      <td>The goal of Treatment Recommendation System is...</td>\n",
       "      <td>Link-to-model4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHP Model for Dental Tourism</td>\n",
       "      <td>AHP Model for Dental Tourism is a model design...</td>\n",
       "      <td>Link-to-model5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AHP Location Selection</td>\n",
       "      <td>AHP Location Selection is the model to perform...</td>\n",
       "      <td>Link-to-model6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group Buying</td>\n",
       "      <td>Group Buying is a model to simulate expected r...</td>\n",
       "      <td>Link-to-model7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Appointment Schedule and Roster Optimization</td>\n",
       "      <td>Appointment Schedule and Roster Optimization i...</td>\n",
       "      <td>Link-to-model8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dentist Performance Analysis</td>\n",
       "      <td>Dentist Performance Analysis is a model to per...</td>\n",
       "      <td>Link-to-model9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MODEL  \\\n",
       "0                Current Asset Value Calculator   \n",
       "1              Potential Asset Value Calculator   \n",
       "2                        Fair Credit Calculator   \n",
       "3               Treatment Recommendation System   \n",
       "4                  AHP Model for Dental Tourism   \n",
       "5                        AHP Location Selection   \n",
       "6                                  Group Buying   \n",
       "7  Appointment Schedule and Roster Optimization   \n",
       "8                  Dentist Performance Analysis   \n",
       "\n",
       "                                         DESCRIPTION            LINK  \n",
       "0  Current Asset Value Calculator aims to develop...  Link-to-model1  \n",
       "1  Potential Asset Value Calculator is designed t...  Link-to-model2  \n",
       "2  Fair Credit Calculator is one initiative among...  Link-to-model3  \n",
       "3  The goal of Treatment Recommendation System is...  Link-to-model4  \n",
       "4  AHP Model for Dental Tourism is a model design...  Link-to-model5  \n",
       "5  AHP Location Selection is the model to perform...  Link-to-model6  \n",
       "6  Group Buying is a model to simulate expected r...  Link-to-model7  \n",
       "7  Appointment Schedule and Roster Optimization i...  Link-to-model8  \n",
       "8  Dentist Performance Analysis is a model to per...  Link-to-model9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop('No', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader\n",
    "\n",
    "# format the data into documents\n",
    "loader = DataFrameLoader(df, page_content_column=\"DESCRIPTION\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# Initialize HuggingFace embedding model\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "model_kwargs = {\"device\": \"mps\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Define a persistence directory for Chroma\n",
    "persist_dir = \"./data_db\"\n",
    "\n",
    "# Create the Chroma database\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents, embedding=hf, persist_directory=persist_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "# from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain.prompts import PromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one of LLMs, in this experiment I use flan-t5\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", device_map='auto')\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model= model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=837,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(path):\n",
    "    # embedding\n",
    "    model_name = \"BAAI/bge-base-en\"\n",
    "    encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "    embedding = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    # Load from disk\n",
    "    vectordb = Chroma(persist_directory=path, embedding_function=embedding)\n",
    "    return vectordb\n",
    "\n",
    "# Load embedding\n",
    "embedding_path = 'db'\n",
    "vectordb = load_embedding_model(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a retriver\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=local_llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nRESULT:')\n",
    "\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['MODEL']+': '+source.metadata['LINK'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Asset Value Calculator\n",
      "\n",
      "\n",
      "RESULT:\n",
      "Potential Asset Value Calculator: Link-to-model2\n",
      "Current Asset Value Calculator: Link-to-model1\n",
      "Treatment Recommendation System: Link-to-model4\n"
     ]
    }
   ],
   "source": [
    "query = \"what is a tool to get predictive analysis?\"\n",
    "# query = \"do you like chocholate?\"\n",
    "# llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)\n",
    "# llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New update on Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'LINK': 'Link-to-model1', 'MODEL': 'Current Asset Value Calculator', 'No': 1}, page_content='Current Asset Value Calculator aims to develop a predictive analytics tool that calculates a clinic’s fair market value by incorporating critical variables. It serves as an essential asset for reducing the risk of\\nunderselling for sellers and overpaying for buyers. Key variables in the model include business performance data from financial statements (such as profit and loss statements and cash flow),\\nas well as customer metrics, including the number of unique patients over time, average revenue per patient, and its variation. Additionally, the model considers the clinic’s physical assets, such as equipment and its usage age, to provide a more comprehensive valuation. By integrating these diverse factors, this model minimizes valuation bias, providing a fairer, data-driven valuation process that benefits both parties in the negotiation. Model definition: Use relevant business results, and other business metrics variable to model more representative valuation of clinic as asset (for acquiring purposes)'),\n",
       " Document(metadata={'LINK': 'Link-to-model4', 'MODEL': 'Treatment Recommendation System', 'No': 4}, page_content=\"The goal of Treatment Recommendation System is to develop a model that recommends specific treatments to existing patients. The resulting recommendation treatment is generated by a recommendation system model that could be developed through several approach, including: ● Through identifying pattern of treatments sequence of existing customer ● Conducting keyword similarity analysis to match potential future treatments’ description with the clinic's treatment catalogue ● Collaborating with subject matter experts (e.g., dentists) to establish a general sequence of treatments and define the most suitable recommendations for each given previous treatment. Additionally, the model will calculate potential revenue gains by estimating the conversion rate of patients who proceed with the recommended treatments. Descriptive analytics will summarize the sales performance of treatments and item codes, both before and after the recommendations are applied. In short, it is a Model that able to generate a recommendation of treatment or a list of recommendation for particular patient based on their profile\"),\n",
       " Document(metadata={'LINK': 'Link-to-model5', 'MODEL': 'AHP Model for Dental Tourism', 'No': 5}, page_content='AHP Model for Dental Tourism is a model designed to perform scoring and rank partner dentist quote to demand which being offered based on proximities for dental tourism program. In order to use the model, an input of potential client or patient preferences and detail is processed and is used to perform optional filtering in the dentist pool that matched the preferences of patient. The model output are alternatives, ranked, of potential dentist for the patient to forgo. AHP algorithm is adopted to rank the best candidate of partner dentist based on predefined criteria of quoted cost, reviews and their participation contribution which respectively possess different weight.')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain\n",
    "chain = prompt | local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauliana/env_py/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Current Asset Value Calculator'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run\n",
    "chain.invoke({\"context\":docs,\"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mauliana/env_py/lib/python3.12/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt_hub_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
